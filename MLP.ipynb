{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from haversine_script import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as p\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import Callback, TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exponential_distance(x,minimum,a=60):\n",
    "\tpositive_x= x-minimum\n",
    "\tnumerator = np.exp(positive_x.div(a))\n",
    "\tdenominator = np.exp(-minimum/a)\n",
    "\texponential_x = numerator/denominator\n",
    "\texponential_x = exponential_x * 1000  #facilitating calculations\n",
    "\tfinal_x = exponential_x\n",
    "\treturn final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_powed_distance(x,minimum,b=1.1):\n",
    "\tpositive_x= x-minimum\n",
    "\tnumerator = positive_x.pow(b)\n",
    "\tdenominator = (-minimum)**(b)\n",
    "\tpowed_x = numerator/denominator\n",
    "\tfinal_x = powed_x\n",
    "\treturn final_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Random Seeding for experiment reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = \"42\"\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) \n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "file = p.read_csv('lorawan_antwerp_2019_dataset.csv')\n",
    "columns = file.columns\n",
    "# x = file[columns[0:68]]\n",
    "# y = file[columns[71:]]\n",
    "x = file[columns[0:72]]\n",
    "x = x.join(file[columns[73]])\n",
    "y = file[columns[72:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum\n",
      "-128.0\n"
     ]
    }
   ],
   "source": [
    "x = x.replace(-200,200)\n",
    "minimum = x.min().min() - 1\n",
    "x = x.replace(200,minimum)\n",
    "print('minimum')\n",
    "print(minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSSI Data representation using Powed Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = get_powed_distance(x,minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91300, 73)\n",
      "(19564, 73)\n",
      "(19565, 73)\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "x_train, x_test_val, y_train, y_test_val = train_test_split(final_x.values, y.values, test_size=0.3, random_state=random_state)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test_val, y_test_val, test_size=0.5, random_state=random_state)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset Normalization [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_features = x_train.shape[1]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "scaler_y = preprocessing.MinMaxScaler().fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.15\n",
    "l2 = 0.00\n",
    "lr = 0.0005\n",
    "epochs = 10000\n",
    "batch_size= 512\n",
    "patience = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1124 07:51:15.605217 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1124 07:51:15.606213 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1124 07:51:15.615190 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1124 07:51:15.751824 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1124 07:51:15.778756 21156 deprecation.py:506] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1124 07:51:16.418043 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=256, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=128, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=128, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(units=2))\n",
    "model.compile(loss='mean_absolute_error',optimizer=Adam(lr=lr))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1124 07:51:17.590934 21156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91300 samples, validate on 19564 samples\n",
      "Epoch 1/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.1431 - val_loss: 0.0514\n",
      "Epoch 2/10000\n",
      "91300/91300 [==============================] - 7s 73us/step - loss: 0.0547 - val_loss: 0.0376\n",
      "Epoch 3/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0467 - val_loss: 0.0412\n",
      "Epoch 4/10000\n",
      "91300/91300 [==============================] - 7s 72us/step - loss: 0.0412 - val_loss: 0.0369\n",
      "Epoch 5/10000\n",
      "91300/91300 [==============================] - 7s 73us/step - loss: 0.0396 - val_loss: 0.0413\n",
      "Epoch 6/10000\n",
      "91300/91300 [==============================] - 7s 73us/step - loss: 0.0377 - val_loss: 0.0254\n",
      "Epoch 7/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0364 - val_loss: 0.0289\n",
      "Epoch 8/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0344 - val_loss: 0.0263\n",
      "Epoch 9/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0335 - val_loss: 0.0319\n",
      "Epoch 10/10000\n",
      "91300/91300 [==============================] - 7s 73us/step - loss: 0.0336 - val_loss: 0.0247\n",
      "Epoch 11/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0322 - val_loss: 0.0282\n",
      "Epoch 12/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0314 - val_loss: 0.0252\n",
      "Epoch 13/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0312 - val_loss: 0.0292\n",
      "Epoch 14/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0306 - val_loss: 0.0289\n",
      "Epoch 15/10000\n",
      "91300/91300 [==============================] - 7s 72us/step - loss: 0.0299 - val_loss: 0.0244\n",
      "Epoch 16/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0294 - val_loss: 0.0244\n",
      "Epoch 17/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0286 - val_loss: 0.0222\n",
      "Epoch 18/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0287 - val_loss: 0.0255\n",
      "Epoch 19/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0277 - val_loss: 0.0238\n",
      "Epoch 20/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0275 - val_loss: 0.0220\n",
      "Epoch 21/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0268 - val_loss: 0.0216\n",
      "Epoch 22/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0261 - val_loss: 0.0209\n",
      "Epoch 23/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0259 - val_loss: 0.0194\n",
      "Epoch 24/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0257 - val_loss: 0.0254\n",
      "Epoch 25/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0259 - val_loss: 0.0222\n",
      "Epoch 26/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0254 - val_loss: 0.0211\n",
      "Epoch 27/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0245 - val_loss: 0.0217\n",
      "Epoch 28/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0246 - val_loss: 0.0203\n",
      "Epoch 29/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0245 - val_loss: 0.0202\n",
      "Epoch 30/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0241 - val_loss: 0.0209\n",
      "Epoch 31/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0242 - val_loss: 0.0213\n",
      "Epoch 32/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0238 - val_loss: 0.0193\n",
      "Epoch 33/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0236 - val_loss: 0.0217\n",
      "Epoch 34/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0231 - val_loss: 0.0220\n",
      "Epoch 35/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0227 - val_loss: 0.0205\n",
      "Epoch 36/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0229 - val_loss: 0.0196\n",
      "Epoch 37/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0230 - val_loss: 0.0232\n",
      "Epoch 38/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0223 - val_loss: 0.0197\n",
      "Epoch 39/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0226 - val_loss: 0.0191\n",
      "Epoch 40/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0223 - val_loss: 0.0202\n",
      "Epoch 41/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0220 - val_loss: 0.0205\n",
      "Epoch 42/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0218 - val_loss: 0.0177\n",
      "Epoch 43/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0218 - val_loss: 0.0180\n",
      "Epoch 44/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0216 - val_loss: 0.0196\n",
      "Epoch 45/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 46/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0212 - val_loss: 0.0178\n",
      "Epoch 47/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0210 - val_loss: 0.0204\n",
      "Epoch 48/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0215 - val_loss: 0.0203\n",
      "Epoch 49/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 50/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0207 - val_loss: 0.0185\n",
      "Epoch 51/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0206 - val_loss: 0.0173\n",
      "Epoch 52/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0205 - val_loss: 0.0192\n",
      "Epoch 53/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0204 - val_loss: 0.0171\n",
      "Epoch 54/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0202 - val_loss: 0.0169\n",
      "Epoch 55/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0202 - val_loss: 0.0185\n",
      "Epoch 56/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 57/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0196 - val_loss: 0.0165\n",
      "Epoch 58/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0198 - val_loss: 0.0173\n",
      "Epoch 59/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0194 - val_loss: 0.0169\n",
      "Epoch 60/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 61/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0198 - val_loss: 0.0174\n",
      "Epoch 62/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 63/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0192 - val_loss: 0.0192\n",
      "Epoch 64/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0193 - val_loss: 0.0173\n",
      "Epoch 65/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0192 - val_loss: 0.0168\n",
      "Epoch 66/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0191 - val_loss: 0.0176\n",
      "Epoch 67/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0188 - val_loss: 0.0166\n",
      "Epoch 68/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0189 - val_loss: 0.0167\n",
      "Epoch 69/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0187 - val_loss: 0.0176\n",
      "Epoch 70/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0189 - val_loss: 0.0170\n",
      "Epoch 71/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0184 - val_loss: 0.0172\n",
      "Epoch 72/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0182 - val_loss: 0.0170\n",
      "Epoch 73/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0186 - val_loss: 0.0163\n",
      "Epoch 74/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0185 - val_loss: 0.0167\n",
      "Epoch 75/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0181 - val_loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0184 - val_loss: 0.0168\n",
      "Epoch 77/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0182 - val_loss: 0.0166\n",
      "Epoch 78/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0183 - val_loss: 0.0176\n",
      "Epoch 79/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0179 - val_loss: 0.0163\n",
      "Epoch 80/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0181 - val_loss: 0.0169\n",
      "Epoch 81/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0177 - val_loss: 0.0155\n",
      "Epoch 82/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0180 - val_loss: 0.0156\n",
      "Epoch 83/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0177 - val_loss: 0.0154\n",
      "Epoch 84/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0177 - val_loss: 0.0160\n",
      "Epoch 85/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0178 - val_loss: 0.0159\n",
      "Epoch 86/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 87/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0176 - val_loss: 0.0157\n",
      "Epoch 88/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0175 - val_loss: 0.0166\n",
      "Epoch 89/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0177 - val_loss: 0.0168\n",
      "Epoch 90/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 91/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 92/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0173 - val_loss: 0.0160\n",
      "Epoch 93/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0172 - val_loss: 0.0158\n",
      "Epoch 94/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0172 - val_loss: 0.0157\n",
      "Epoch 95/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 96/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0171 - val_loss: 0.0157\n",
      "Epoch 97/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 98/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0169 - val_loss: 0.0151\n",
      "Epoch 99/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0168 - val_loss: 0.0154\n",
      "Epoch 100/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 101/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 102/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0169 - val_loss: 0.0154\n",
      "Epoch 103/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0169 - val_loss: 0.0156\n",
      "Epoch 104/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0168 - val_loss: 0.0152\n",
      "Epoch 105/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0169 - val_loss: 0.0150\n",
      "Epoch 106/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0167 - val_loss: 0.0163\n",
      "Epoch 107/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0167 - val_loss: 0.0160\n",
      "Epoch 108/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0166 - val_loss: 0.0158\n",
      "Epoch 109/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0168 - val_loss: 0.0164\n",
      "Epoch 110/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0165 - val_loss: 0.0152\n",
      "Epoch 111/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 112/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 113/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0165 - val_loss: 0.0160\n",
      "Epoch 114/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0157\n",
      "Epoch 115/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 116/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0163 - val_loss: 0.0157\n",
      "Epoch 117/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0164 - val_loss: 0.0150\n",
      "Epoch 118/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0163 - val_loss: 0.0156\n",
      "Epoch 119/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 120/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0162 - val_loss: 0.0155\n",
      "Epoch 121/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0160 - val_loss: 0.0154\n",
      "Epoch 122/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 123/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 124/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 125/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0160 - val_loss: 0.0152\n",
      "Epoch 126/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 127/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0160 - val_loss: 0.0145\n",
      "Epoch 128/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 129/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0160 - val_loss: 0.0148\n",
      "Epoch 130/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 131/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0154\n",
      "Epoch 132/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 133/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 134/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 135/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 136/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 137/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 138/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 139/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 140/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 141/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 142/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0155 - val_loss: 0.0144\n",
      "Epoch 143/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 144/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 145/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0155 - val_loss: 0.0166A: 1s \n",
      "Epoch 146/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 147/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 148/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 149/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 150/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 151/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 152/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 153/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 154/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 155/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 156/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 157/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 158/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 159/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0151 - val_loss: 0.0140\n",
      "Epoch 160/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 161/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 162/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 163/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0152 - val_loss: 0.0147\n",
      "Epoch 164/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0151 - val_loss: 0.0140\n",
      "Epoch 165/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 166/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 167/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 168/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 169/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 170/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 171/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 172/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 173/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 174/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0149 - val_loss: 0.0144\n",
      "Epoch 175/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 176/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 177/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 178/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 179/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0147 - val_loss: 0.0142\n",
      "Epoch 180/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 181/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0149 - val_loss: 0.0144\n",
      "Epoch 182/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 183/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 184/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 185/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 186/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0146 - val_loss: 0.0160\n",
      "Epoch 187/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 188/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 189/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 190/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 191/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 192/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0145 - val_loss: 0.0158\n",
      "Epoch 193/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 194/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0145 - val_loss: 0.0148\n",
      "Epoch 195/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 196/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 197/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 198/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 199/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 200/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 201/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0145 - val_loss: 0.0158\n",
      "Epoch 202/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 203/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 204/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 205/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 206/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 207/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 208/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 209/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0145\n",
      "Epoch 210/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 211/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 212/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 213/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 214/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 215/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0143 - val_loss: 0.0137\n",
      "Epoch 216/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 217/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 218/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 219/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 220/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 221/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 222/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 223/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 224/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 225/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 226/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 227/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 228/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 229/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 230/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 231/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 232/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 233/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 234/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 235/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 236/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 237/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 238/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 239/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 240/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 241/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 242/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 243/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 244/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 245/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 246/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 247/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 248/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 249/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 250/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 251/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 252/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 253/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 254/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0137 - val_loss: 0.0140\n",
      "Epoch 255/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 256/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 257/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 258/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 259/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 260/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 261/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 262/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 263/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 264/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 265/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 266/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0136 - val_loss: 0.0140\n",
      "Epoch 267/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0136 - val_loss: 0.0139\n",
      "Epoch 268/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 269/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 270/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0136 - val_loss: 0.0143\n",
      "Epoch 271/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 272/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 273/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 274/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 275/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 276/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 277/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 278/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 279/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 280/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 281/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0157\n",
      "Epoch 282/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0136 - val_loss: 0.0137\n",
      "Epoch 283/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 284/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0141\n",
      "Epoch 285/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0135 - val_loss: 0.0138\n",
      "Epoch 286/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 287/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0134 - val_loss: 0.0141\n",
      "Epoch 288/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0135 - val_loss: 0.0158\n",
      "Epoch 289/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 290/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 291/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 292/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0137\n",
      "Epoch 293/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 294/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 295/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 296/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 297/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 298/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0139\n",
      "Epoch 299/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 300/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 301/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 302/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 303/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0133 - val_loss: 0.0139\n",
      "Epoch 304/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 305/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 306/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 307/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0134 - val_loss: 0.0141\n",
      "Epoch 308/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 309/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 310/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 311/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 312/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 313/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 314/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 315/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 316/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 317/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 318/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 319/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 320/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 321/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0132 - val_loss: 0.0139\n",
      "Epoch 322/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 323/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 324/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 325/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 326/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 327/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 328/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 329/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 330/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 331/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 332/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 333/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 334/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 335/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 336/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 337/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 338/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0130 - val_loss: 0.0137\n",
      "Epoch 339/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0136\n",
      "Epoch 340/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 341/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 342/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 343/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 344/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 345/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 346/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 347/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 348/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 349/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 350/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 351/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 352/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 353/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 354/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 355/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 356/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 357/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 358/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 359/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 360/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 361/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 362/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 363/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 364/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 365/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 366/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 367/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 368/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 369/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 370/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 371/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 372/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 373/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 374/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 375/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 376/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 377/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 378/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 379/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 380/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 381/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 382/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 383/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 384/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 385/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 386/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 387/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 388/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 389/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 390/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 391/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 392/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 393/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 394/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 395/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 396/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 397/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 398/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 399/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 400/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 401/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 402/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 403/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 404/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 405/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 406/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 407/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 408/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 409/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 410/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 411/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 412/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 413/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 414/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 415/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 416/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 417/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 418/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 419/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 420/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 421/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 422/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 423/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 424/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 425/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 426/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 427/10000\n",
      "91300/91300 [==============================] - 11s 123us/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 428/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 429/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 430/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 431/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 432/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 433/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 434/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 435/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 436/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 437/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 438/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 439/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 440/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 441/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0134\n",
      "Epoch 442/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 443/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 444/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 445/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 446/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 447/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 448/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 449/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 450/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 451/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 452/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 453/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 454/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 455/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 456/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 457/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 458/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 459/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 460/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 461/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 462/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 463/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 464/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 465/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 466/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 467/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 468/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 469/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 470/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 471/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 472/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 473/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 474/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 475/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 476/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 477/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 478/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 479/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 480/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 481/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 482/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 483/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 484/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 485/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 486/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 487/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 488/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 489/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 490/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 491/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 492/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 493/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 494/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 495/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0120 - val_loss: 0.0136\n",
      "Epoch 496/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 497/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 498/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 499/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 500/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 501/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 502/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 503/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 504/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 505/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 506/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 507/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 508/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 509/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 510/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 511/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 512/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 513/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 514/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 515/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 516/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 517/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 518/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 519/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 521/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 522/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 523/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 524/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 525/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0122 - val_loss: 0.0140\n",
      "Epoch 526/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 527/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 528/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 529/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 530/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0136\n",
      "Epoch 531/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 532/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 533/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 534/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 535/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 536/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 537/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 538/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 539/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 540/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 541/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 542/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "Epoch 543/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 544/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 545/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 546/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 547/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 548/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 549/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 550/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 551/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 552/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 553/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 554/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 555/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0143\n",
      "Epoch 556/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 557/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 558/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 559/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 560/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 561/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 562/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 563/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 564/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 565/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 566/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 567/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 568/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 569/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 570/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 571/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 572/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 573/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 574/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 575/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 576/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 577/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 578/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 579/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 580/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 581/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 582/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 583/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 584/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0148\n",
      "Epoch 585/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 586/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 587/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 588/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0151\n",
      "Epoch 589/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 590/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 591/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 592/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 593/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 594/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 595/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 596/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 597/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 598/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 599/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 600/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 601/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 602/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 603/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 604/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 605/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 606/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 607/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 608/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 609/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 610/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 611/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0135\n",
      "Epoch 612/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 613/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 614/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 615/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 616/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 617/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0119 - val_loss: 0.0143\n",
      "Epoch 618/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 619/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 620/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 621/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 622/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 623/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 624/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 625/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 626/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 627/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 628/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 629/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0139\n",
      "Epoch 630/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 631/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 632/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 633/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 634/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 635/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 636/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 637/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 638/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 639/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 640/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 641/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 642/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 643/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 644/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 645/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 646/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 647/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 648/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 649/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 650/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 651/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 652/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 653/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 654/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 655/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 656/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 657/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 658/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 659/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 660/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 661/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 662/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 663/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 664/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 665/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 666/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 667/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 668/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 669/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 670/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 671/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 672/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 673/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 674/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 675/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 676/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 677/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 678/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 679/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 680/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 681/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 682/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 683/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 684/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 685/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 686/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 687/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 688/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 689/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 690/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 691/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0114 - val_loss: 0.0129\n",
      "Epoch 692/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 693/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 694/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 695/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 696/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 697/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 698/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 699/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 700/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 701/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 702/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 703/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 704/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 705/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 706/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 707/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 708/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 709/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 710/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 711/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 712/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 713/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 714/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 715/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 716/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 717/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 718/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 719/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 720/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 721/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 722/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 723/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 724/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 725/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 726/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 727/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 728/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 729/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 730/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 731/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 732/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 733/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 734/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 735/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 736/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 737/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 738/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 739/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 740/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 741/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 742/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 743/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 744/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 745/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 746/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 747/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 748/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 749/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 750/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 751/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 752/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 753/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 754/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 755/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 756/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 757/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 758/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 759/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 760/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 761/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 762/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 763/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 764/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 765/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 766/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 767/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 768/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 769/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 770/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 771/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 772/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 773/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 774/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 775/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 776/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 777/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 778/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 779/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 780/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 781/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 782/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 783/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 784/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 785/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 786/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 787/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 788/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 789/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 790/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 791/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 792/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 793/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 794/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 795/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 796/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 797/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 798/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 799/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 800/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 801/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 802/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 803/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 804/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 805/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 806/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 807/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 808/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 809/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 810/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 811/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 812/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 813/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 814/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 815/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 816/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 817/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 818/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 819/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 820/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 821/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 822/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 823/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 824/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 825/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0139\n",
      "Epoch 826/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 827/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0111 - val_loss: 0.0140\n",
      "Epoch 828/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 829/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 830/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 831/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0112 - val_loss: 0.0142\n",
      "Epoch 832/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 833/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 834/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 835/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 836/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 837/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 838/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 839/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 840/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 841/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 842/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 843/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 844/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 845/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 846/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 847/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 848/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 849/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 850/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 851/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 852/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 853/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 854/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0139\n",
      "Epoch 855/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 856/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0138\n",
      "Epoch 857/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 858/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 859/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 860/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 861/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 862/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 863/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 864/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 865/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0138\n",
      "Epoch 866/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 867/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 868/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 869/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 870/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 871/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 872/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 873/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 874/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 875/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 876/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 877/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 878/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 879/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 880/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 881/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 882/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 883/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 884/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 885/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 886/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 887/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0142\n",
      "Epoch 888/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 889/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 890/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 891/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 892/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 893/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 894/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 895/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 896/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 897/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 898/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 899/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 900/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 901/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 902/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 903/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 904/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 905/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 906/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0138\n",
      "Epoch 907/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 908/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 909/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 910/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0140\n",
      "Epoch 911/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 912/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 913/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 914/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 915/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 916/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 917/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 918/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 919/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 920/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 921/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 922/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 923/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 924/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 925/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 926/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 927/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 928/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 929/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 930/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 931/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 932/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 933/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 934/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 935/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 936/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 937/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 938/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 939/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 940/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 941/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 942/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 943/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 944/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 945/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 946/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 947/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 948/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 949/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 950/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 951/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 952/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 953/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 954/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 955/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 956/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 957/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 958/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 959/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 960/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 961/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 962/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 963/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 964/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 965/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 966/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 967/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 968/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 969/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 970/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 971/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 972/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 973/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 974/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 975/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 976/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 977/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 978/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 979/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 980/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 981/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0108 - val_loss: 0.0137\n",
      "Epoch 982/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 983/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 984/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 985/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 986/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 987/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 988/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 989/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 990/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 991/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 992/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 993/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 994/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 995/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 996/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 997/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 998/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 999/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 1000/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1001/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0142\n",
      "Epoch 1002/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 1003/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 1004/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1005/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 1006/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0131\n",
      "Epoch 1007/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 1008/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 1009/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1010/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1011/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1012/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1013/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1014/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1015/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 1016/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1017/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1018/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 1019/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 1020/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 1021/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 1022/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1023/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1024/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1025/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 1026/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1027/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 1028/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 1029/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1030/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 1031/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1032/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1033/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1034/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1035/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1036/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1037/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 1038/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 1039/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1040/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 1041/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 1042/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 1043/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1044/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1045/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1046/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1047/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 1048/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1049/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1050/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1051/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1052/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1053/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 1054/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 1055/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1056/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1057/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1058/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1059/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 1060/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 1061/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1062/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1063/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1064/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 1065/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1066/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1067/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1068/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1069/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1070/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1071/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1072/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1073/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 1074/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1075/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1076/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1077/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 1078/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1079/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1080/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1081/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1082/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1083/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1084/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1085/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 1086/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1087/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1088/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 1089/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1090/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1091/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1092/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1093/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1094/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1095/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1096/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1097/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 1098/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1099/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 1100/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1101/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1102/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1103/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1104/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1105/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1106/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1107/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1108/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1109/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 1110/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1111/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1112/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1113/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1114/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1115/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1116/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1117/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 1118/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1119/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1120/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 1121/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1122/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 1123/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 1124/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1125/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1126/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 1127/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1128/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1129/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1130/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 1131/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1132/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1133/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1134/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 1135/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 1136/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1137/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 1138/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1139/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1140/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 1141/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 1142/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 1143/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1144/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 1145/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1146/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1147/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 1148/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1149/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1150/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1151/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 1152/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 1153/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 1154/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 1155/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1156/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1157/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1158/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1159/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1160/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1161/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1162/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 1163/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1164/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1165/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1166/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1167/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1168/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1169/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1170/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1171/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1172/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1173/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1174/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1175/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 1176/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1177/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1178/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1179/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1180/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 1181/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1182/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1183/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 1184/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1185/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1187/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1188/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1189/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 1190/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 1191/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1192/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1193/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1194/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1195/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1196/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1197/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1198/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1199/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1200/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0136\n",
      "Epoch 1201/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 1202/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1203/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1204/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1205/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1206/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1207/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1208/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1209/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 1210/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 1211/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1212/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1213/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1214/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1215/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1216/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1217/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1218/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1219/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1220/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1221/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1222/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1223/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 1224/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1225/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1226/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1227/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1228/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1229/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1230/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1231/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1232/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 1233/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1234/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1235/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1236/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 1237/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1238/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 1239/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1240/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1241/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1242/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 1243/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1244/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1245/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1246/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 1247/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1248/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1249/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 1250/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 1251/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1252/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1253/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1254/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1255/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1256/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1257/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 1258/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1259/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0104 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1260/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1261/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1262/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1263/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1264/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1265/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1266/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1267/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1268/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 1269/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 1270/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1271/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1272/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1273/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1274/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1275/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1276/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 1277/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1278/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1279/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1280/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1281/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1282/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1283/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1284/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1285/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1286/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1287/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1288/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1289/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 1290/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1291/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1292/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1293/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1294/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1295/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1296/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1297/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1298/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 1299/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1300/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1301/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1302/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1303/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1304/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1305/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1306/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1307/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 1308/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1309/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1310/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1311/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1312/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 1313/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1314/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1315/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1316/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1317/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1318/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 1319/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1320/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1321/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 1322/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 1323/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1324/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1325/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 1326/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 1327/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1328/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1329/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1330/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1331/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1332/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1333/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1334/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1335/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1336/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1337/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1338/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 1339/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1340/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1341/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1342/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1343/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 1344/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1345/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1346/10000\n",
      "91300/91300 [==============================] - 10s 115us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1347/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 1348/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1349/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 1350/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1351/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1352/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1353/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 1354/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1355/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 1356/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1357/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0103 - val_loss: 0.0140\n",
      "Epoch 1358/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1359/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1360/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1361/10000\n",
      "91300/91300 [==============================] - 13s 139us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1362/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1363/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 1364/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1365/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1366/10000\n",
      "91300/91300 [==============================] - 11s 117us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1367/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 1368/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1369/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 1370/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 1371/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1372/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1373/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 1374/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1375/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1376/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1377/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1378/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1379/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1380/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1381/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1382/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0103 - val_loss: 0.0143\n",
      "Epoch 1383/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1384/10000\n",
      "91300/91300 [==============================] - 11s 121us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1385/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1386/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1387/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1388/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1389/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1390/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1391/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1392/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1393/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1394/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1395/10000\n",
      "91300/91300 [==============================] - 11s 117us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1396/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0103 - val_loss: 0.0139\n",
      "Epoch 1397/10000\n",
      "91300/91300 [==============================] - 11s 121us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1398/10000\n",
      "91300/91300 [==============================] - 11s 122us/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1399/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1400/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1401/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1402/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1403/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1404/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1405/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 1406/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1407/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1408/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 1409/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1410/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1411/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1412/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1413/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1414/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1415/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 1416/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1417/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1418/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1419/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1420/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1421/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1422/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1423/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 1424/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1425/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1426/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1427/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1428/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1429/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1430/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1431/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1432/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1433/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1434/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 1435/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1436/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1437/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1438/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1439/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1440/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1441/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1442/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1443/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1444/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1445/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1446/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 1447/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1448/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 1449/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1450/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 1451/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1452/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1453/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1454/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1455/10000\n",
      "91300/91300 [==============================] - 12s 136us/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 1456/10000\n",
      "91300/91300 [==============================] - 11s 126us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1457/10000\n",
      "91300/91300 [==============================] - 11s 119us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1458/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 1459/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 1460/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 1461/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1462/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1463/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1464/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 1465/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1466/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1467/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1468/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1469/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1470/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 1471/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 1472/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1473/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1474/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1475/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1476/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1477/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1478/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1479/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1480/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0104 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1481/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1482/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1483/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1484/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1485/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1486/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1487/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1488/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1489/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1490/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1491/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1492/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1493/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 1494/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1495/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1496/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1497/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1498/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1499/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1500/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1501/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1502/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1503/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1504/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0138\n",
      "Epoch 1505/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1506/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1507/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1508/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 1509/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1510/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1511/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1512/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1513/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1514/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1515/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1516/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1517/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1518/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1519/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1520/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1521/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1522/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1523/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1524/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1525/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1526/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1527/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1528/10000\n",
      "91300/91300 [==============================] - 13s 148us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1529/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1530/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 1531/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1532/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0139\n",
      "Epoch 1533/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1534/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1535/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 1536/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1537/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1538/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0140\n",
      "Epoch 1539/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1540/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1541/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1542/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1543/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1544/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1545/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1546/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1547/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1548/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1549/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1550/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1551/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1552/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1553/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1554/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1555/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1556/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1557/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1558/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1559/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1560/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1561/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1562/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1563/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1564/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1565/10000\n",
      "91300/91300 [==============================] - 12s 127us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1566/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1567/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1568/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1569/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1570/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1571/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1572/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 1573/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 1574/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 1575/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1576/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1577/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 1578/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1579/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1580/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1581/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1582/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1583/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1584/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 1585/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1586/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1587/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 1588/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 1589/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1590/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1591/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1592/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1593/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0101 - val_loss: 0.0139\n",
      "Epoch 1594/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1595/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1596/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1597/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1598/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1599/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 1600/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1601/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1602/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1603/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1604/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1605/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1606/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1607/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1608/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1609/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 1610/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1611/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1612/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1613/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1614/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1615/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1616/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1617/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1618/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0101 - val_loss: 0.0138\n",
      "Epoch 1619/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0102 - val_loss: 0.0139\n",
      "Epoch 1620/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1621/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1622/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1623/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1624/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1625/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1626/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 1628/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1629/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1630/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1631/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0138\n",
      "Epoch 1632/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1633/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 1634/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1635/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1636/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1637/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1638/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1639/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 1640/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1641/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1642/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1643/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1644/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1645/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1646/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1647/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1648/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1649/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1650/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 1651/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1652/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1653/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1654/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1655/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1656/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1657/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1658/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1659/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0102 - val_loss: 0.0141\n",
      "Epoch 1660/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 1661/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1662/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 1663/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1664/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1665/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1666/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1667/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1668/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1669/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1670/10000\n",
      "91300/91300 [==============================] - 12s 135us/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 1671/10000\n",
      "91300/91300 [==============================] - 11s 126us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1672/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1673/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1674/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0101 - val_loss: 0.0140\n",
      "Epoch 1675/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 1676/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1677/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1678/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1679/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1680/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1681/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1682/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1683/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 1684/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1685/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1686/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1687/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 1688/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1689/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1690/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0136\n",
      "Epoch 1691/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1692/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1693/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1694/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0136\n",
      "Epoch 1695/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1696/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1697/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 1698/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 1699/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1700/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0099 - val_loss: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1702/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1703/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1704/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 1705/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1706/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1707/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1708/10000\n",
      "91300/91300 [==============================] - 12s 127us/step - loss: 0.0101 - val_loss: 0.0131\n",
      "Epoch 1709/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1710/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0099 - val_loss: 0.0134\n",
      "Epoch 1711/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1712/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 1713/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1714/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1715/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1716/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1717/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1718/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 1719/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 1720/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1721/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1722/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1723/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 1724/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 1725/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1726/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1727/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0101 - val_loss: 0.0140\n",
      "Epoch 1728/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1729/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 1730/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1731/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 1732/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1733/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 1734/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 1735/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1736/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 1737/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 1738/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 1739/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1740/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1741/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1742/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1743/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 1744/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1745/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1746/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1747/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 1748/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 01748: early stopping\n"
     ]
    }
   ],
   "source": [
    "cb =[EarlyStopping(monitor='val_loss', patience=patience, verbose =1, restore_best_weights=True)]\n",
    "history = model.fit(x_train, y_train,validation_data=(x_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1, callbacks= cb)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plot Training Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('training_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Predict Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test, batch_size=batch_size) \n",
    "y_predict_in_val = model.predict(x_val, batch_size=batch_size)\n",
    "y_predict_in_train = model.predict(x_train, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revert the Representation from normalize to lat-long coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict_in_train = scaler_y.inverse_transform(y_predict_in_train)\n",
    "y_predict_in_val = scaler_y.inverse_transform(y_predict_in_val)\n",
    "y_train = scaler_y.inverse_transform(y_train)\n",
    "y_val = scaler_y.inverse_transform(y_val)\n",
    "y_test = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Haversine Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set mean error: 91.12\n",
      "Train set median error: 31.98\n",
      "Train set75th perc error: 71.51\n",
      "Val set mean error: 132.99\n",
      "Val set median error: 41.30\n",
      "Val set 75th perc.  error: 126.85\n",
      "Test set mean error: 134.11\n",
      "Test set median error: 40.94\n",
      "Test set  75th perc. error: 124.41\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'mean')))\n",
    "print(\"Train set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'median')))\n",
    "print(\"Train set75th perc error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'percentile',75)))\n",
    "print(\"Val set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'mean')))\n",
    "print(\"Val set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'median')))\n",
    "print(\"Val set 75th perc.  error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'percentile',75)))\n",
    "print(\"Test set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'mean')))\n",
    "print(\"Test set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'median')))\n",
    "print(\"Test set  75th perc. error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'percentile',75)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment completed!!!\n"
     ]
    }
   ],
   "source": [
    "test_error_list = calculate_pairwise_error_list(y_predict,y_test)\n",
    "p.DataFrame(test_error_list).to_csv(\"mlp_test_error_list.csv\")\n",
    "print(\"Experiment completed!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras library import  for Saving and loading model and weights\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(\"Baseline.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Baseline.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
