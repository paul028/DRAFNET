{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from haversine_script import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as p\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import Callback, TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exponential_distance(x,minimum,a=60):\n",
    "\tpositive_x= x-minimum\n",
    "\tnumerator = np.exp(positive_x.div(a))\n",
    "\tdenominator = np.exp(-minimum/a)\n",
    "\texponential_x = numerator/denominator\n",
    "\texponential_x = exponential_x * 1000  #facilitating calculations\n",
    "\tfinal_x = exponential_x\n",
    "\treturn final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_powed_distance(x,minimum,b=1.1):\n",
    "\tpositive_x= x-minimum\n",
    "\tnumerator = positive_x.pow(b)\n",
    "\tdenominator = (-minimum)**(b)\n",
    "\tpowed_x = numerator/denominator\n",
    "\tfinal_x = powed_x\n",
    "\treturn final_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Random Seeding for experiment reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = \"42\"\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name=\"MLP+PCA=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "components=10 # select the top 10 gateways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) \n",
    "session_conf.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "file = p.read_csv('lorawan_antwerp_2019_dataset.csv')\n",
    "columns = file.columns\n",
    "# x = file[columns[0:68]]\n",
    "# y = file[columns[71:]]\n",
    "x = file[columns[0:72]]\n",
    "x = x.join(file[columns[73]])\n",
    "y = file[columns[72:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum\n",
      "-128.0\n"
     ]
    }
   ],
   "source": [
    "x = x.replace(-200,200)\n",
    "minimum = x.min().min() - 1\n",
    "x = x.replace(200,minimum)\n",
    "print('minimum')\n",
    "print(minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSSI Data representation using Powed Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = get_powed_distance(x,minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91300, 73)\n",
      "(19564, 73)\n",
      "(19565, 73)\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "x_train, x_test_val, y_train, y_test_val = train_test_split(final_x.values, y.values, test_size=0.3, random_state=random_state)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test_val, y_test_val, test_size=0.5, random_state=random_state)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset Normalization [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "scaler_y = preprocessing.MinMaxScaler().fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components =components) \n",
    "  \n",
    "x_train = pca.fit_transform(x_train) \n",
    "x_val = pca.transform(x_val)\n",
    "x_test = pca.transform(x_test)\n",
    "explained_variance = pca.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91300, 10)\n",
      "(19564, 10)\n",
      "(19565, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "n_of_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.15\n",
    "l2 = 0.00\n",
    "lr = 0.0005\n",
    "epochs = 10000\n",
    "batch_size= 512\n",
    "patience = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MLP Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1126 11:08:59.277971 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1126 11:08:59.283957 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1126 11:08:59.297917 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1126 11:08:59.599112 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1126 11:08:59.652967 26156 deprecation.py:506] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1126 11:09:00.999396 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=1024, input_dim=n_of_features, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=256, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=128, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout, seed=random_state))\n",
    "model.add(Dense(units=128, kernel_regularizer=regularizers.l2(l2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(units=2))\n",
    "model.compile(loss='mean_absolute_error',optimizer=Adam(lr=lr))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:09:03.260321 26156 deprecation_wrapper.py:119] From C:\\Users\\Paul Vincent Nonat\\AppData\\Local\\conda\\conda\\envs\\nonat_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91300 samples, validate on 19564 samples\n",
      "Epoch 1/10000\n",
      "91300/91300 [==============================] - 15s 163us/step - loss: 0.1413 - val_loss: 0.0863\n",
      "Epoch 2/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0637 - val_loss: 0.0541\n",
      "Epoch 3/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0513 - val_loss: 0.0486\n",
      "Epoch 4/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0466 - val_loss: 0.0362\n",
      "Epoch 5/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0430 - val_loss: 0.0324\n",
      "Epoch 6/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0418 - val_loss: 0.0342\n",
      "Epoch 7/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0393 - val_loss: 0.0297\n",
      "Epoch 8/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0383 - val_loss: 0.0284\n",
      "Epoch 9/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0367 - val_loss: 0.0294\n",
      "Epoch 10/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0362 - val_loss: 0.0295\n",
      "Epoch 11/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0359 - val_loss: 0.0292\n",
      "Epoch 12/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0347 - val_loss: 0.0275\n",
      "Epoch 13/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0336 - val_loss: 0.0285\n",
      "Epoch 14/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0337 - val_loss: 0.0280\n",
      "Epoch 15/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0327 - val_loss: 0.0269\n",
      "Epoch 16/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0322 - val_loss: 0.0289\n",
      "Epoch 17/10000\n",
      "91300/91300 [==============================] - 13s 139us/step - loss: 0.0317 - val_loss: 0.0260\n",
      "Epoch 18/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 19/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0314 - val_loss: 0.0273\n",
      "Epoch 20/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0301 - val_loss: 0.0340\n",
      "Epoch 21/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0306 - val_loss: 0.0264\n",
      "Epoch 22/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0297 - val_loss: 0.0254\n",
      "Epoch 23/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0297 - val_loss: 0.0257\n",
      "Epoch 24/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0289 - val_loss: 0.0280\n",
      "Epoch 25/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0287 - val_loss: 0.0238\n",
      "Epoch 26/10000\n",
      "91300/91300 [==============================] - 14s 152us/step - loss: 0.0289 - val_loss: 0.0233\n",
      "Epoch 27/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0280 - val_loss: 0.0235\n",
      "Epoch 28/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0283 - val_loss: 0.0251\n",
      "Epoch 29/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0278 - val_loss: 0.0265\n",
      "Epoch 30/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0276 - val_loss: 0.0250\n",
      "Epoch 31/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0273 - val_loss: 0.0233\n",
      "Epoch 32/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0272 - val_loss: 0.0234\n",
      "Epoch 33/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0267 - val_loss: 0.0228\n",
      "Epoch 34/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0263 - val_loss: 0.0226\n",
      "Epoch 35/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0269 - val_loss: 0.0237\n",
      "Epoch 36/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0263 - val_loss: 0.0248\n",
      "Epoch 37/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0261 - val_loss: 0.0217\n",
      "Epoch 38/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0255 - val_loss: 0.0233\n",
      "Epoch 39/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0255 - val_loss: 0.0226\n",
      "Epoch 40/10000\n",
      "91300/91300 [==============================] - 12s 127us/step - loss: 0.0251 - val_loss: 0.0232\n",
      "Epoch 41/10000\n",
      "91300/91300 [==============================] - 11s 119us/step - loss: 0.0252 - val_loss: 0.0235\n",
      "Epoch 42/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0250 - val_loss: 0.0220\n",
      "Epoch 43/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0250 - val_loss: 0.0245\n",
      "Epoch 44/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0249 - val_loss: 0.0207\n",
      "Epoch 45/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0245 - val_loss: 0.0217\n",
      "Epoch 46/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0242 - val_loss: 0.0221\n",
      "Epoch 47/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0243 - val_loss: 0.0229\n",
      "Epoch 48/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0241 - val_loss: 0.0209\n",
      "Epoch 49/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0238 - val_loss: 0.0199\n",
      "Epoch 50/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 51/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0235 - val_loss: 0.0208\n",
      "Epoch 52/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0240 - val_loss: 0.0221\n",
      "Epoch 53/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0236 - val_loss: 0.0219\n",
      "Epoch 54/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0234 - val_loss: 0.0203\n",
      "Epoch 55/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0231 - val_loss: 0.0199\n",
      "Epoch 56/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 57/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0229 - val_loss: 0.0198\n",
      "Epoch 58/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 59/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0227 - val_loss: 0.0200\n",
      "Epoch 60/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0226 - val_loss: 0.0207\n",
      "Epoch 61/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0224 - val_loss: 0.0204\n",
      "Epoch 62/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0226 - val_loss: 0.0196\n",
      "Epoch 63/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0224 - val_loss: 0.0187\n",
      "Epoch 64/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0222 - val_loss: 0.0199\n",
      "Epoch 65/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0221 - val_loss: 0.0199\n",
      "Epoch 66/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0219 - val_loss: 0.0190\n",
      "Epoch 67/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 68/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0217 - val_loss: 0.0214\n",
      "Epoch 69/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0217 - val_loss: 0.0222\n",
      "Epoch 70/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0219 - val_loss: 0.0210\n",
      "Epoch 71/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0216 - val_loss: 0.0192\n",
      "Epoch 72/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0215 - val_loss: 0.0211\n",
      "Epoch 73/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0214 - val_loss: 0.0195\n",
      "Epoch 74/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0212 - val_loss: 0.0189\n",
      "Epoch 75/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0212 - val_loss: 0.0207\n",
      "Epoch 76/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0213 - val_loss: 0.0192\n",
      "Epoch 77/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 78/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0212 - val_loss: 0.0192\n",
      "Epoch 79/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0210 - val_loss: 0.0197\n",
      "Epoch 80/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 81/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 82/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0208 - val_loss: 0.0214\n",
      "Epoch 83/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0210 - val_loss: 0.0192\n",
      "Epoch 84/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0206 - val_loss: 0.0188\n",
      "Epoch 85/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0206 - val_loss: 0.0182\n",
      "Epoch 86/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 87/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0207 - val_loss: 0.0195\n",
      "Epoch 88/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0203 - val_loss: 0.0193\n",
      "Epoch 89/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0204 - val_loss: 0.0180\n",
      "Epoch 90/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0203 - val_loss: 0.0186\n",
      "Epoch 91/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 92/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0203 - val_loss: 0.0181\n",
      "Epoch 93/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0202 - val_loss: 0.0186\n",
      "Epoch 94/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0201 - val_loss: 0.0184\n",
      "Epoch 95/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0200 - val_loss: 0.0188\n",
      "Epoch 96/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0200 - val_loss: 0.0182\n",
      "Epoch 97/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 98/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0198 - val_loss: 0.0189\n",
      "Epoch 99/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0199 - val_loss: 0.0185\n",
      "Epoch 100/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0198 - val_loss: 0.0188\n",
      "Epoch 101/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0198 - val_loss: 0.0180\n",
      "Epoch 102/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0197 - val_loss: 0.0173\n",
      "Epoch 103/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0196 - val_loss: 0.0187\n",
      "Epoch 104/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0196 - val_loss: 0.0176\n",
      "Epoch 105/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 106/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0195 - val_loss: 0.0182\n",
      "Epoch 107/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0197 - val_loss: 0.0182\n",
      "Epoch 108/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0193 - val_loss: 0.0176\n",
      "Epoch 109/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0195 - val_loss: 0.0177\n",
      "Epoch 110/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0193 - val_loss: 0.0176\n",
      "Epoch 111/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0194 - val_loss: 0.0179\n",
      "Epoch 112/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0194 - val_loss: 0.0182\n",
      "Epoch 113/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0192 - val_loss: 0.0186\n",
      "Epoch 114/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0194 - val_loss: 0.0177\n",
      "Epoch 115/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 116/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 117/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 118/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0190 - val_loss: 0.0179\n",
      "Epoch 119/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0190 - val_loss: 0.0173\n",
      "Epoch 120/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0190 - val_loss: 0.0170\n",
      "Epoch 121/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0190 - val_loss: 0.0170\n",
      "Epoch 122/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0189 - val_loss: 0.0177\n",
      "Epoch 123/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0188 - val_loss: 0.0173\n",
      "Epoch 124/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0188 - val_loss: 0.0177\n",
      "Epoch 125/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0188 - val_loss: 0.0179\n",
      "Epoch 126/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0189 - val_loss: 0.0178\n",
      "Epoch 127/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0187 - val_loss: 0.0174\n",
      "Epoch 128/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 129/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0186 - val_loss: 0.0173\n",
      "Epoch 130/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0186 - val_loss: 0.0169\n",
      "Epoch 131/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0186 - val_loss: 0.0166\n",
      "Epoch 132/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 133/10000\n",
      "91300/91300 [==============================] - 11s 115us/step - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 134/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 135/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0185 - val_loss: 0.0168\n",
      "Epoch 136/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 137/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 138/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 139/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0185 - val_loss: 0.0179\n",
      "Epoch 140/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0185 - val_loss: 0.0174\n",
      "Epoch 141/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 142/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0185 - val_loss: 0.0169\n",
      "Epoch 143/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0183 - val_loss: 0.0168\n",
      "Epoch 144/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0183 - val_loss: 0.0175\n",
      "Epoch 145/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0182 - val_loss: 0.0172\n",
      "Epoch 146/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0181 - val_loss: 0.0179\n",
      "Epoch 147/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0182 - val_loss: 0.0173\n",
      "Epoch 148/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0182 - val_loss: 0.0173\n",
      "Epoch 150/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 151/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 152/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0181 - val_loss: 0.0163\n",
      "Epoch 153/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0180 - val_loss: 0.0166\n",
      "Epoch 154/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0182 - val_loss: 0.0167\n",
      "Epoch 155/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0182 - val_loss: 0.0165\n",
      "Epoch 156/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0180 - val_loss: 0.0170\n",
      "Epoch 157/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0180 - val_loss: 0.0175\n",
      "Epoch 158/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0180 - val_loss: 0.0169\n",
      "Epoch 159/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0180 - val_loss: 0.0163\n",
      "Epoch 160/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0178 - val_loss: 0.0165\n",
      "Epoch 161/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 162/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0179 - val_loss: 0.0169\n",
      "Epoch 163/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0178 - val_loss: 0.0169\n",
      "Epoch 164/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 165/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0179 - val_loss: 0.0162\n",
      "Epoch 166/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0177 - val_loss: 0.0176\n",
      "Epoch 167/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0176 - val_loss: 0.0167\n",
      "Epoch 168/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0177 - val_loss: 0.0165\n",
      "Epoch 169/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0177 - val_loss: 0.0164\n",
      "Epoch 170/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0176 - val_loss: 0.0164\n",
      "Epoch 171/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0176 - val_loss: 0.0169\n",
      "Epoch 172/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 173/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 174/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0176 - val_loss: 0.0160\n",
      "Epoch 175/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0174 - val_loss: 0.0163\n",
      "Epoch 176/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0169\n",
      "Epoch 177/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0176 - val_loss: 0.0162\n",
      "Epoch 178/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 179/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0162\n",
      "Epoch 180/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0176 - val_loss: 0.0168\n",
      "Epoch 181/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 182/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0175 - val_loss: 0.0163\n",
      "Epoch 183/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0161\n",
      "Epoch 184/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0174 - val_loss: 0.0163\n",
      "Epoch 185/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0160\n",
      "Epoch 186/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0173 - val_loss: 0.0166\n",
      "Epoch 187/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0168\n",
      "Epoch 188/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0174 - val_loss: 0.0162\n",
      "Epoch 189/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0174 - val_loss: 0.0175\n",
      "Epoch 190/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0173 - val_loss: 0.0167\n",
      "Epoch 191/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0174 - val_loss: 0.0174\n",
      "Epoch 192/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0174 - val_loss: 0.0166\n",
      "Epoch 193/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0161\n",
      "Epoch 194/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 195/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0160\n",
      "Epoch 196/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0175 - val_loss: 0.0159\n",
      "Epoch 197/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 198/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0173 - val_loss: 0.0166\n",
      "Epoch 199/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 200/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 201/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0162\n",
      "Epoch 202/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0165\n",
      "Epoch 203/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0159\n",
      "Epoch 204/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 205/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0163\n",
      "Epoch 206/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 207/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0161\n",
      "Epoch 208/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0169 - val_loss: 0.0160\n",
      "Epoch 209/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0170 - val_loss: 0.0166\n",
      "Epoch 210/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 211/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0172 - val_loss: 0.0166\n",
      "Epoch 212/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0171 - val_loss: 0.0166\n",
      "Epoch 213/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0170 - val_loss: 0.0161\n",
      "Epoch 214/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0168 - val_loss: 0.0161\n",
      "Epoch 215/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0170 - val_loss: 0.0175\n",
      "Epoch 216/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0169 - val_loss: 0.0164\n",
      "Epoch 217/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 218/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0170 - val_loss: 0.0159\n",
      "Epoch 219/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 220/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 221/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 222/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0160\n",
      "Epoch 223/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 224/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 225/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0168 - val_loss: 0.0156\n",
      "Epoch 226/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0168 - val_loss: 0.0158\n",
      "Epoch 227/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 228/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0167 - val_loss: 0.0162\n",
      "Epoch 229/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0162\n",
      "Epoch 230/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 231/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0168 - val_loss: 0.0162\n",
      "Epoch 232/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 233/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0168 - val_loss: 0.0163\n",
      "Epoch 234/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 235/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0166 - val_loss: 0.0160\n",
      "Epoch 236/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0170\n",
      "Epoch 237/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 238/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0166 - val_loss: 0.0162\n",
      "Epoch 239/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 240/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0156\n",
      "Epoch 241/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 242/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0167 - val_loss: 0.0156\n",
      "Epoch 243/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0166 - val_loss: 0.0160\n",
      "Epoch 244/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 245/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0165 - val_loss: 0.0158\n",
      "Epoch 246/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 247/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 248/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0167 - val_loss: 0.0157\n",
      "Epoch 249/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0166 - val_loss: 0.0159\n",
      "Epoch 250/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0164 - val_loss: 0.0156\n",
      "Epoch 251/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0160\n",
      "Epoch 252/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 253/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 254/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 255/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0164\n",
      "Epoch 256/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 257/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0164 - val_loss: 0.0176\n",
      "Epoch 258/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0165 - val_loss: 0.0161\n",
      "Epoch 259/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0153\n",
      "Epoch 260/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 261/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 262/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0154\n",
      "Epoch 263/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 264/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 265/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0155\n",
      "Epoch 266/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 267/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0163 - val_loss: 0.0154\n",
      "Epoch 268/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0163 - val_loss: 0.0162\n",
      "Epoch 269/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 270/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0157\n",
      "Epoch 271/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0167\n",
      "Epoch 272/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 273/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0165\n",
      "Epoch 274/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 275/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 276/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 277/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 278/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0152\n",
      "Epoch 279/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 280/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 281/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 282/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 283/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 284/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0160 - val_loss: 0.0170\n",
      "Epoch 285/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 286/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 287/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 288/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 289/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 290/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 291/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 292/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 293/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 294/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 295/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 296/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0160 - val_loss: 0.0161\n",
      "Epoch 297/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 298/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 299/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 300/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0160 - val_loss: 0.0160\n",
      "Epoch 301/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 302/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 303/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0159 - val_loss: 0.0160\n",
      "Epoch 304/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 305/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 306/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 307/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0159 - val_loss: 0.0156\n",
      "Epoch 308/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 309/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 310/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0158 - val_loss: 0.0156\n",
      "Epoch 311/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0158 - val_loss: 0.0153\n",
      "Epoch 312/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 313/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 314/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 315/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 316/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 317/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 318/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 319/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 320/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 321/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 322/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 323/10000\n",
      "91300/91300 [==============================] - 12s 132us/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 324/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 325/10000\n",
      "91300/91300 [==============================] - 12s 136us/step - loss: 0.0156 - val_loss: 0.0158\n",
      "Epoch 326/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 327/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 328/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0157 - val_loss: 0.0158\n",
      "Epoch 329/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 330/10000\n",
      "91300/91300 [==============================] - 11s 117us/step - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 331/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0155 - val_loss: 0.0156\n",
      "Epoch 332/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0158 - val_loss: 0.0159\n",
      "Epoch 333/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 334/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0156 - val_loss: 0.0158\n",
      "Epoch 335/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 336/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 337/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 338/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 339/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 340/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 341/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0155 - val_loss: 0.0153\n",
      "Epoch 342/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 343/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 344/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0156 - val_loss: 0.0162\n",
      "Epoch 345/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 346/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0156 - val_loss: 0.0154\n",
      "Epoch 347/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 348/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0155 - val_loss: 0.0156\n",
      "Epoch 349/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 350/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 351/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 352/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 353/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 354/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 355/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 356/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 357/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 358/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 359/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 360/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 361/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0154 - val_loss: 0.0164\n",
      "Epoch 362/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 363/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 364/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 365/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 366/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0154 - val_loss: 0.0162\n",
      "Epoch 367/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 368/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 369/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 370/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 372/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 373/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 374/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0154 - val_loss: 0.0155\n",
      "Epoch 375/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 376/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 377/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 378/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 379/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 380/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 381/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 382/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 383/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 384/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 385/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 386/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 387/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0152 - val_loss: 0.0169\n",
      "Epoch 388/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 389/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 390/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 391/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0151 - val_loss: 0.0153\n",
      "Epoch 392/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 393/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 394/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 395/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 396/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 397/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 398/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 399/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 400/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 401/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 402/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0153\n",
      "Epoch 403/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 404/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 405/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 406/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 407/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 408/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 409/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 410/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 411/10000\n",
      "91300/91300 [==============================] - 11s 117us/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 412/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 413/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 414/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 415/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 416/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 417/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 418/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 419/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 420/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 421/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 422/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 423/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 424/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 425/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 426/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 427/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 428/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 429/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 430/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 431/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 432/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 433/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 434/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 435/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 436/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 437/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 438/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 439/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 440/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 441/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 442/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 443/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 444/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 445/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 446/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 447/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0163\n",
      "Epoch 448/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 449/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 450/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 451/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 452/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 453/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 454/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 455/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 456/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 457/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 458/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 459/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 460/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 461/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 462/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 463/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0148 - val_loss: 0.0150\n",
      "Epoch 464/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 465/10000\n",
      "91300/91300 [==============================] - 11s 121us/step - loss: 0.0149 - val_loss: 0.0152\n",
      "Epoch 466/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 467/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 468/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 469/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 470/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 471/10000\n",
      "91300/91300 [==============================] - 12s 130us/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 472/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 473/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0148 - val_loss: 0.0160\n",
      "Epoch 474/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 475/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0145 - val_loss: 0.0158\n",
      "Epoch 476/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 477/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 478/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 479/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 480/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 481/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 482/10000\n",
      "91300/91300 [==============================] - 11s 122us/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 483/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 484/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 485/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 486/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 487/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 488/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 489/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 490/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 491/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 492/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 493/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 494/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 495/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 496/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 497/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0145 - val_loss: 0.0152\n",
      "Epoch 498/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 499/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 500/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 501/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 502/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 503/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 504/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 505/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 506/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 507/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 508/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 509/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 510/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 511/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 512/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0144 - val_loss: 0.0149\n",
      "Epoch 513/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 514/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 515/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0166\n",
      "Epoch 516/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 517/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 518/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 520/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 521/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 522/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 523/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 524/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 525/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 526/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 527/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 528/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 529/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 530/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 531/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 532/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 533/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 534/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 535/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 536/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 537/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 538/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 539/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 540/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 541/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 542/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 543/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 544/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0143 - val_loss: 0.0155\n",
      "Epoch 545/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 546/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 547/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 548/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 549/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 550/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 551/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 552/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0143 - val_loss: 0.0152\n",
      "Epoch 553/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 554/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 555/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 556/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 557/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 558/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 559/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 560/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 561/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 562/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 563/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 564/10000\n",
      "91300/91300 [==============================] - 12s 129us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 565/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 566/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 567/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 568/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 569/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 570/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 571/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0143 - val_loss: 0.0152\n",
      "Epoch 572/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 573/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 574/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 575/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 576/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 577/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 578/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 579/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 580/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 581/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0143 - val_loss: 0.0149\n",
      "Epoch 582/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 583/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0142 - val_loss: 0.0152\n",
      "Epoch 584/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 585/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 586/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 587/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0142 - val_loss: 0.0152\n",
      "Epoch 588/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 589/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 590/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 591/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 592/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 593/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 594/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 595/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 596/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 597/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 598/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 599/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 600/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 601/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0142 - val_loss: 0.0153\n",
      "Epoch 602/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 603/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0161\n",
      "Epoch 604/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 605/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 606/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 607/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 608/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0143 - val_loss: 0.0154\n",
      "Epoch 609/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 610/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0142 - val_loss: 0.0156\n",
      "Epoch 611/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 612/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 613/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 614/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 615/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 616/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 617/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 618/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 619/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 620/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 621/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 622/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 623/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 624/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 625/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 626/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0142 - val_loss: 0.0153\n",
      "Epoch 627/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 628/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0142 - val_loss: 0.0145\n",
      "Epoch 629/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0152\n",
      "Epoch 630/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 631/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 632/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 633/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 634/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 635/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 636/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 637/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 638/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 639/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 640/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 641/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 642/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 643/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 644/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 645/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 646/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 647/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0140 - val_loss: 0.0152\n",
      "Epoch 648/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 649/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0152\n",
      "Epoch 650/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 651/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 652/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 653/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 654/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 655/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 656/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 657/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0167\n",
      "Epoch 658/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 659/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 660/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 661/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 662/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 663/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 664/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 665/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 666/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 667/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 668/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 669/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 670/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 671/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0140 - val_loss: 0.0152\n",
      "Epoch 672/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 673/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 674/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 675/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 676/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 677/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 678/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 679/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0140 - val_loss: 0.0166\n",
      "Epoch 680/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 681/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 682/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0139 - val_loss: 0.0152\n",
      "Epoch 683/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 684/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0140 - val_loss: 0.0149\n",
      "Epoch 685/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 686/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 687/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 688/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 689/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 690/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 691/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 692/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 693/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 694/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 695/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 696/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 697/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0139 - val_loss: 0.0149\n",
      "Epoch 698/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 699/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 700/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 701/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 702/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 703/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 704/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 705/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 706/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 707/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 708/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 709/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 710/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 711/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 712/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 713/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 714/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 715/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 716/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 717/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 718/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 719/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 720/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 721/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 722/10000\n",
      "91300/91300 [==============================] - 12s 126us/step - loss: 0.0136 - val_loss: 0.0159\n",
      "Epoch 723/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 724/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 725/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 726/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 727/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 728/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 729/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 730/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 731/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 732/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0138 - val_loss: 0.0147\n",
      "Epoch 733/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0138 - val_loss: 0.0153\n",
      "Epoch 734/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 735/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 736/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 737/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 738/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 739/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 740/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0136 - val_loss: 0.0142\n",
      "Epoch 741/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0137 - val_loss: 0.0151\n",
      "Epoch 742/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 743/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 744/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 745/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 746/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 747/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 748/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 749/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 750/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0156\n",
      "Epoch 751/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 752/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 753/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 754/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0151\n",
      "Epoch 755/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 756/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 757/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 758/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 759/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 760/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 761/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 762/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 763/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 764/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 765/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0137 - val_loss: 0.0151\n",
      "Epoch 766/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 767/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 768/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 769/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 770/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0137 - val_loss: 0.0146\n",
      "Epoch 771/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 772/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 773/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 774/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 775/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 776/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 777/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 778/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 779/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 780/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 781/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0137 - val_loss: 0.0153\n",
      "Epoch 782/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 783/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0137 - val_loss: 0.0143\n",
      "Epoch 784/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 785/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0136 - val_loss: 0.0151\n",
      "Epoch 786/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 787/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 788/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 789/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 790/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 791/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 792/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 793/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 794/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 795/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 796/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 797/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 798/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 799/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 800/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 801/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 802/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 803/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 804/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 805/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 806/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 807/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 808/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 809/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 810/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 811/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 812/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 813/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 814/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0136 - val_loss: 0.0143\n",
      "Epoch 815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 816/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 817/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 818/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0136 - val_loss: 0.0157\n",
      "Epoch 819/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 820/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 821/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 822/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 823/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 824/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 825/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 826/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 827/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 828/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0154\n",
      "Epoch 829/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 830/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 831/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 832/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 833/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 834/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 835/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 836/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 837/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 838/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 839/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 840/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 841/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 842/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 843/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 844/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 845/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 846/10000\n",
      "91300/91300 [==============================] - 11s 122us/step - loss: 0.0134 - val_loss: 0.0150\n",
      "Epoch 847/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 848/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 849/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 850/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 851/10000\n",
      "91300/91300 [==============================] - 10s 115us/step - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 852/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 853/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0136 - val_loss: 0.0146\n",
      "Epoch 854/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 855/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0134 - val_loss: 0.0150\n",
      "Epoch 856/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 857/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 858/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 859/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 860/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 861/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 862/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 863/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 864/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 865/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 866/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 867/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 868/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 869/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 870/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 871/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 872/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 873/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 874/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 875/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 876/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 877/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 878/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 879/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 880/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 881/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 882/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 883/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 884/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 885/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 886/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 887/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 888/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0134 - val_loss: 0.0147\n",
      "Epoch 889/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0134 - val_loss: 0.0150\n",
      "Epoch 890/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 891/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0134 - val_loss: 0.0150\n",
      "Epoch 892/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 893/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0143\n",
      "Epoch 894/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 895/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 896/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 897/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 898/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 899/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 900/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 901/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 902/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 903/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 904/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 905/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 906/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 907/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 908/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 909/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 910/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 911/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 912/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 913/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 914/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 915/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 916/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 917/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 918/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 919/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 920/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 921/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 922/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 923/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 924/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 925/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 926/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 927/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 928/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 929/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 930/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0134 - val_loss: 0.0155\n",
      "Epoch 931/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 932/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 933/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 934/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 935/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0133 - val_loss: 0.0151\n",
      "Epoch 936/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 937/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 938/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 939/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 940/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 941/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 942/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 943/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 944/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 945/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 946/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 947/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 948/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 949/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 950/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 951/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 952/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 953/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 954/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 955/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 956/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 957/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 958/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 959/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0131 - val_loss: 0.0146\n",
      "Epoch 960/10000\n",
      "91300/91300 [==============================] - 10s 113us/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 961/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0131 - val_loss: 0.0157\n",
      "Epoch 962/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 963/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 964/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 965/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 966/10000\n",
      "91300/91300 [==============================] - 12s 128us/step - loss: 0.0131 - val_loss: 0.0143\n",
      "Epoch 967/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 968/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 969/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 970/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 971/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 972/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 973/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 974/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 975/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0133 - val_loss: 0.0148\n",
      "Epoch 976/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 977/10000\n",
      "91300/91300 [==============================] - 12s 127us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 978/10000\n",
      "91300/91300 [==============================] - 12s 133us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 979/10000\n",
      "91300/91300 [==============================] - 14s 151us/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 980/10000\n",
      "91300/91300 [==============================] - 11s 118us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 981/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 982/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 983/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 984/10000\n",
      "91300/91300 [==============================] - 11s 125us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 985/10000\n",
      "91300/91300 [==============================] - 12s 136us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 986/10000\n",
      "91300/91300 [==============================] - 12s 127us/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 987/10000\n",
      "91300/91300 [==============================] - 11s 116us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 988/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 989/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 990/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 991/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0131 - val_loss: 0.0143\n",
      "Epoch 992/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 993/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 994/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 995/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0132 - val_loss: 0.0158\n",
      "Epoch 996/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 997/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 998/10000\n",
      "91300/91300 [==============================] - 11s 119us/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 999/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 1000/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 1001/10000\n",
      "91300/91300 [==============================] - 10s 107us/step - loss: 0.0131 - val_loss: 0.0149\n",
      "Epoch 1002/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 1003/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1004/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 1005/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 1006/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 1007/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 1008/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 1009/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 1010/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 1011/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 1012/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0131 - val_loss: 0.0146\n",
      "Epoch 1013/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 1014/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 1015/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0131 - val_loss: 0.0140\n",
      "Epoch 1016/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 1017/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 1018/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 1019/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 1020/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 1021/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 1022/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 1023/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0131 - val_loss: 0.0146\n",
      "Epoch 1024/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 1025/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 1026/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1027/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 1028/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1029/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 1030/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 1031/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1032/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 1033/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 1034/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 1035/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 1036/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0131 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1037/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 1038/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 1039/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 1040/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0142\n",
      "Epoch 1041/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 1042/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 1043/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1044/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1045/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 1046/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 1047/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 1048/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 1049/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 1050/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0130 - val_loss: 0.0151\n",
      "Epoch 1051/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 1052/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1053/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 1054/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 1055/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1056/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 1057/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 1058/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 1059/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1060/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 1061/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1062/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 1063/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 1064/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0130 - val_loss: 0.0152\n",
      "Epoch 1065/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 1066/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1067/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1068/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1069/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 1070/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1071/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1072/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1073/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 1074/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 1075/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 1076/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1077/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 1078/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 1079/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1080/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 1081/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 1082/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 1083/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1084/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 1085/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0130 - val_loss: 0.0148\n",
      "Epoch 1086/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 1087/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1088/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1089/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 1090/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1091/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1092/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1093/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 1094/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 1095/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 1096/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 1097/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1098/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 1099/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 1100/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 1101/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 1102/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 1103/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 1104/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1105/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1106/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0142\n",
      "Epoch 1107/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1108/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 1109/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1110/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1111/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1112/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 1113/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 1114/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 1115/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0148\n",
      "Epoch 1116/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1117/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1118/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 1119/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1120/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1121/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1122/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1123/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1124/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1125/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 1126/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1127/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1128/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 1129/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1130/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 1131/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1132/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 1133/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 1134/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 1135/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0129 - val_loss: 0.0144\n",
      "Epoch 1136/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1137/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 1138/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 1139/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 1140/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1141/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1142/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 1143/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 1144/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 1145/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1146/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 1147/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1148/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1149/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 1150/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 1151/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1152/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1153/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1154/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 1155/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 1156/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 1157/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1158/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1159/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 1160/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1161/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 1162/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1163/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1164/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 1165/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1166/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1167/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 1168/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1169/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1170/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1171/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0127 - val_loss: 0.0142s: 0\n",
      "Epoch 1172/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0149\n",
      "Epoch 1173/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 1174/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1175/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 1176/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1177/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1178/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 1179/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1180/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 1181/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1182/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1183/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1184/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1185/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 1186/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 1187/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0150\n",
      "Epoch 1188/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1189/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 1190/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1191/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 1192/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 1193/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1194/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 1195/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1196/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1197/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 1198/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 1199/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 1200/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 1201/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1202/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 1203/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1204/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 1205/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 1206/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 1207/10000\n",
      "91300/91300 [==============================] - 9s 93us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1208/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 1209/10000\n",
      "91300/91300 [==============================] - 10s 112us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 1210/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1211/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 1212/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1213/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1214/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 1215/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 1216/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1217/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 1218/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1219/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 1220/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0148\n",
      "Epoch 1221/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1222/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 1223/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1224/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1225/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 1226/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1227/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0128 - val_loss: 0.0148 ETA: 0s - loss: 0.\n",
      "Epoch 1228/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1229/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 1230/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1231/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1232/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1233/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1234/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 1235/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 1236/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1237/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 1238/10000\n",
      "91300/91300 [==============================] - 8s 93us/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 1239/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1240/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1241/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1242/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 1243/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1244/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 1245/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1246/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1247/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1248/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1249/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 1250/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1251/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1252/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 1253/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 1254/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1255/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 1256/10000\n",
      "91300/91300 [==============================] - 10s 110us/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 1257/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1258/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 1259/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 1260/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1261/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 1262/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 1263/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1264/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1265/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 1266/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1267/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1268/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1269/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1270/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1271/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 1272/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 1273/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 1274/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1275/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1276/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 1277/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 1278/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1279/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1280/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1281/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1282/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 1283/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 1284/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1285/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1286/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 1287/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1288/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1289/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1290/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 1291/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1292/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1293/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 1294/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1295/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 1296/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 1297/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 1298/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1299/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1300/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1301/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 1302/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1303/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 1304/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 1305/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 1306/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1307/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1308/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1309/10000\n",
      "91300/91300 [==============================] - 10s 111us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1310/10000\n",
      "91300/91300 [==============================] - 10s 115us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 1311/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0126 - val_loss: 0.0145\n",
      "Epoch 1312/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 1313/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1314/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 1315/10000\n",
      "91300/91300 [==============================] - 10s 114us/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 1316/10000\n",
      "91300/91300 [==============================] - 10s 109us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1317/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1318/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1319/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1320/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1321/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 1322/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 1323/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 1324/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 1325/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1326/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 1327/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1328/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1329/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1330/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1331/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 1332/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1333/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1334/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 1335/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 1336/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 1337/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1338/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 1339/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 1340/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 1341/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 1342/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 1343/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0126 - val_loss: 0.0148\n",
      "Epoch 1344/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1345/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1346/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1347/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 1348/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1349/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1350/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1351/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 1352/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 1353/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 1354/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1355/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1356/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1357/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1358/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1359/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1360/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1361/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 1362/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1363/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 1364/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1365/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1366/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 1367/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1368/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 1369/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1370/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1371/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 1372/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1373/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1374/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1375/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1376/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1377/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0124 - val_loss: 0.0140\n",
      "Epoch 1378/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1379/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 1380/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 1381/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1382/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0125 - val_loss: 0.0149\n",
      "Epoch 1383/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1384/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1385/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1386/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1387/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1388/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1389/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1390/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1391/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 1392/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1393/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1394/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1395/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 1396/10000\n",
      "91300/91300 [==============================] - 10s 108us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1397/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1398/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1399/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1400/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1401/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1402/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1403/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1404/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0123 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1405/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1406/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1407/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1408/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1409/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 1410/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1411/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 1412/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1413/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1414/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1415/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1416/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1417/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1418/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1419/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 1420/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1421/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1422/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1423/10000\n",
      "91300/91300 [==============================] - 7s 74us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1424/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1425/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1426/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0144\n",
      "Epoch 1427/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1428/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 1429/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 1430/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1431/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1432/10000\n",
      "91300/91300 [==============================] - 7s 75us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1433/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1434/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1435/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0154\n",
      "Epoch 1436/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1437/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1438/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1439/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1440/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1441/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 1442/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1443/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1444/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 1445/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1446/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1447/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1448/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 1449/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1450/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1451/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 1452/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1453/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 1454/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1455/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 1456/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1457/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1458/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0150\n",
      "Epoch 1459/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1460/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1461/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1462/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1463/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1464/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1465/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1466/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1467/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1468/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 1469/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1470/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1471/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1472/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 1473/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1474/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1475/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0150\n",
      "Epoch 1476/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1477/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 1478/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1479/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1480/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1481/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1482/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1483/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 1484/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1485/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 1486/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1487/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1488/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 1489/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1490/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1491/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 1492/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 1493/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1494/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1495/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1496/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1497/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 1498/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 1499/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1500/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1501/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1502/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1503/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1504/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1505/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1506/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 1507/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 1508/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1509/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1510/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1511/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1512/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1513/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0146\n",
      "Epoch 1514/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1515/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1516/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1517/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0150\n",
      "Epoch 1518/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1519/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1520/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 1521/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1522/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1523/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1524/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1525/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1526/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 1527/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 1528/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1529/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1530/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1531/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1532/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1533/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 1534/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1535/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1536/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1537/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1538/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1539/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1540/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 1541/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1542/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1543/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1544/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0144\n",
      "Epoch 1545/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1546/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1547/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1548/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1549/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 1550/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1551/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1552/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1553/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 1554/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1555/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 1556/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1557/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 1558/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1559/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1560/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1561/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1562/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1563/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1564/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1565/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 1566/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1567/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1568/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1569/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1570/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1571/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1572/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 1573/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1574/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1575/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0144\n",
      "Epoch 1576/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1577/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 1578/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1579/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1580/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1581/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 1582/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1583/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1584/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1585/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1586/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1587/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0123 - val_loss: 0.0146\n",
      "Epoch 1588/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 1589/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1590/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1591/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1592/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1593/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 1594/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1595/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1596/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1597/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1598/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 1599/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1600/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1601/10000\n",
      "91300/91300 [==============================] - 7s 76us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 1602/10000\n",
      "91300/91300 [==============================] - 7s 77us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1603/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1604/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1605/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 1606/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1607/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1608/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1609/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1610/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1611/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1612/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1613/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 1614/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1615/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1616/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0122 - val_loss: 0.0154\n",
      "Epoch 1617/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1618/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 1619/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1620/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1621/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1622/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1623/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0122 - val_loss: 0.0151\n",
      "Epoch 1624/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1625/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1626/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1627/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 1628/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 1629/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 1630/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1631/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1632/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1633/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1634/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1635/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1636/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1637/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0139\n",
      "Epoch 1638/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1639/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1640/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1641/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 1642/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1643/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1644/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1645/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 1646/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 1647/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 1648/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1649/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1650/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1651/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 1652/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 1653/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1654/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1655/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1656/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1657/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1658/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1659/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 1660/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1661/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1662/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1663/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1664/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1665/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1666/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1667/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1668/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1669/10000\n",
      "91300/91300 [==============================] - 7s 78us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1670/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 1671/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1672/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1673/10000\n",
      "91300/91300 [==============================] - 7s 80us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1674/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1675/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1676/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1677/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 1678/10000\n",
      "91300/91300 [==============================] - 7s 79us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1679/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1680/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1681/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 1682/10000\n",
      "91300/91300 [==============================] - 8s 82us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1683/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1684/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1685/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1686/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1687/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 1688/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1689/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1690/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 1691/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1692/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1693/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 1694/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1695/10000\n",
      "91300/91300 [==============================] - 7s 82us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1696/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1697/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 1698/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1699/10000\n",
      "91300/91300 [==============================] - 7s 81us/step - loss: 0.0121 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1700/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1701/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 1702/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1703/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 1704/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1705/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1706/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1707/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1708/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1709/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1710/10000\n",
      "91300/91300 [==============================] - 10s 105us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1711/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 1712/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1713/10000\n",
      "91300/91300 [==============================] - 9s 95us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1714/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 1715/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 1716/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 1717/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 1718/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 1719/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1720/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1721/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1722/10000\n",
      "91300/91300 [==============================] - 10s 104us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1723/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1724/10000\n",
      "91300/91300 [==============================] - 9s 99us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1725/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1726/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1727/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1728/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 1729/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 1730/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1731/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 1732/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1733/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 1734/10000\n",
      "91300/91300 [==============================] - 9s 96us/step - loss: 0.0122 - val_loss: 0.0153\n",
      "Epoch 1735/10000\n",
      "91300/91300 [==============================] - 9s 98us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1736/10000\n",
      "91300/91300 [==============================] - 9s 101us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1737/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1738/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 1739/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1740/10000\n",
      "91300/91300 [==============================] - 9s 103us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1741/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1742/10000\n",
      "91300/91300 [==============================] - 9s 100us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 1743/10000\n",
      "91300/91300 [==============================] - 9s 104us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 1744/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 1745/10000\n",
      "91300/91300 [==============================] - 10s 106us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1746/10000\n",
      "91300/91300 [==============================] - 9s 102us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1747/10000\n",
      "91300/91300 [==============================] - 9s 97us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1748/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1749/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 1750/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1751/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1752/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 1753/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 1754/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1755/10000\n",
      "91300/91300 [==============================] - 8s 91us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1756/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1757/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 1758/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1759/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0139\n",
      "Epoch 1760/10000\n",
      "91300/91300 [==============================] - 9s 94us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1761/10000\n",
      "91300/91300 [==============================] - 8s 89us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1762/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 1763/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1764/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1765/10000\n",
      "91300/91300 [==============================] - 8s 83us/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 1766/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 1767/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 1768/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1769/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 1770/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1771/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 1772/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1773/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 1774/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 1775/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1776/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 1777/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 1778/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 1779/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 1780/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1781/10000\n",
      "91300/91300 [==============================] - 8s 90us/step - loss: 0.0122 - val_loss: 0.0143\n",
      "Epoch 1782/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1783/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1784/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1785/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 1786/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 1787/10000\n",
      "91300/91300 [==============================] - 8s 85us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 1788/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 1789/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1790/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 1791/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1792/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 1793/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 1794/10000\n",
      "91300/91300 [==============================] - 8s 84us/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 1795/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 1796/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 1797/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 1798/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 1799/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0120 - val_loss: 0.0151\n",
      "Epoch 1800/10000\n",
      "91300/91300 [==============================] - 8s 92us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1801/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 1802/10000\n",
      "91300/91300 [==============================] - 8s 87us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 1803/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 1804/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0119 - val_loss: 0.0147\n",
      "Epoch 1805/10000\n",
      "91300/91300 [==============================] - 8s 88us/step - loss: 0.0120 - val_loss: 0.0146\n",
      "Epoch 1806/10000\n",
      "91300/91300 [==============================] - 8s 86us/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 01806: early stopping\n"
     ]
    }
   ],
   "source": [
    "cb =[EarlyStopping(monitor='val_loss', patience=patience, verbose =1, restore_best_weights=True)]\n",
    "history = model.fit(x_train, y_train,validation_data=(x_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1, callbacks= cb)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plot Training Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('training_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Predict Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test, batch_size=batch_size) \n",
    "y_predict_in_val = model.predict(x_val, batch_size=batch_size)\n",
    "y_predict_in_train = model.predict(x_train, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revert the Representation from normalize to lat-long coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict_in_train = scaler_y.inverse_transform(y_predict_in_train)\n",
    "y_predict_in_val = scaler_y.inverse_transform(y_predict_in_val)\n",
    "y_train = scaler_y.inverse_transform(y_train)\n",
    "y_val = scaler_y.inverse_transform(y_val)\n",
    "y_test = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Haversine Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set mean error: 103.55\n",
      "Train set median error: 37.08\n",
      "Train set75th perc error: 92.55\n",
      "Val set mean error: 147.17\n",
      "Val set median error: 47.58\n",
      "Val set 75th perc.  error: 157.22\n",
      "Test set mean error: 149.01\n",
      "Test set median error: 48.09\n",
      "Test set  75th perc. error: 156.44\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'mean')))\n",
    "print(\"Train set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'median')))\n",
    "print(\"Train set75th perc error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_train, y_train,'percentile',75)))\n",
    "print(\"Val set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'mean')))\n",
    "print(\"Val set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'median')))\n",
    "print(\"Val set 75th perc.  error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict_in_val, y_val,'percentile',75)))\n",
    "print(\"Test set mean error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'mean')))\n",
    "print(\"Test set median error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'median')))\n",
    "print(\"Test set  75th perc. error: {:.2f}\".format(my_custom_haversine_error_stats(y_predict, y_test,'percentile',75)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment completed!!!\n"
     ]
    }
   ],
   "source": [
    "test_error_list = calculate_pairwise_error_list(y_predict,y_test)\n",
    "p.DataFrame(test_error_list).to_csv(trial_name+\"_error.csv\")\n",
    "print(\"Experiment completed!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras library import  for Saving and loading model and weights\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(trial_name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(trial_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
